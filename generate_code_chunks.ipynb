{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-logging\n",
    "import logging\n",
    "import google.cloud.logging\n",
    "import google.cloud.logging_v2 as logging_v2\n",
    "from os import environ\n",
    "\n",
    "client = logging_v2.client.Client()\n",
    "\n",
    "# set the format for the log\n",
    "google_log_format= logging.Formatter(\n",
    "fmt='%(name)s | %(module)s | %(funcName)s | %(message)s',\n",
    "datefmt='%Y-%m-$dT%H:%M:%S')\n",
    "\n",
    "\n",
    "handler = client.get_default_handler()\n",
    "handler.setFormatter(google_log_format)\n",
    "\n",
    "cloud_logger = logging.getLogger(\"vertex-ai-notebook-logger\")\n",
    "cloud_logger.setLevel(\"CRITICAL\")\n",
    "cloud_logger.addHandler(handler)\n",
    "\n",
    "log = logging.getLogger(\"vertex-ai-notebook-logger\")\n",
    "log.critical(\"This is a log from a Vertex AI Notebook!\")\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "os.environ['MKL_NUM_THREADS'] = \"1\"\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.distribution import MultiprocessingDistributor\n",
    "from tqdm import tqdm\n",
    "from tsfresh import extract_relevant_features\n",
    "import tsfresh\n",
    "\n",
    "path = 'gcs/hms_applied_cv/'\n",
    "offset = 1\n",
    "path_for_file = path + f'hms-harmful-brain-activity-classification/new_features{offset}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'hms-harmful-brain-activity-classification/train.csv')\n",
    "# Concat the last 6 columns into one\n",
    "df['concatenated_scores'] = df.iloc[:, -6:].apply(lambda x: ''.join(x.astype(str)), axis=1)\n",
    "# Create column of False\n",
    "df['is_center'] = False\n",
    "\n",
    "# Sort by eeg_id and then eeg_sub_id\n",
    "df = df.sort_values(['eeg_id', 'eeg_sub_id'])\n",
    "\n",
    "# Iterate over the rows\n",
    "counter = 0\n",
    "start_row_index = 0\n",
    "for i in range(len(df)):\n",
    "    if i == 0:\n",
    "        counter += 1\n",
    "        continue\n",
    "    \n",
    "    # Check if the concatenated_scores is the same as the previous row\n",
    "    if df.at[i, 'concatenated_scores'] == df.at[i-1, 'concatenated_scores'] and df.at[i, 'eeg_id'] == df.at[i-1, 'eeg_id']:\n",
    "        counter += 1\n",
    "    else:\n",
    "        row_to_edit = 0\n",
    "        if counter == 1:\n",
    "            row_to_edit = start_row_index\n",
    "        else:\n",
    "            row_to_edit = int((counter - 1) / 2) + start_row_index\n",
    "        df.at[row_to_edit, 'is_center'] = True\n",
    "        start_row_index = i\n",
    "        counter = 1\n",
    "\n",
    "\n",
    "row_to_edit = int((counter - 1) / 2) + start_row_index\n",
    "df.at[row_to_edit, 'is_center'] = True\n",
    "\n",
    "df.to_csv(path + 'hms-harmful-brain-activity-classification/cleaned_train.csv')\n",
    "cleaned_train = df\n",
    "cleaned_train = pd.read_csv(path + 'hms-harmful-brain-activity-classification/cleaned_train.csv')\n",
    "cleaned_train = cleaned_train[cleaned_train['is_center'] == True]\n",
    "log.critical(\"Cleaned_Train Created!\")\n",
    "# cleaned_train.loc[(cleaned_train['eeg_id'] == 568657) & (cleaned_train['is_center'] == True), 'expert_consensus'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WAVELET = 'db8'\n",
    "NAMES = ['LL','LP','RP','RR']\n",
    "\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "\n",
    "# DENOISE FUNCTION\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def denoise(x, wavelet='haar', level=1):    \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "\n",
    "    ret=pywt.waverec(coeff, wavelet, mode='per')\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def spectrogram_from_eeg(ids, display=False):\n",
    "    for i, eeg_id in tqdm(enumerate(ids)):\n",
    "        ids_data = np.array([], dtype=np.int64)\n",
    "        times_data = np.array([])\n",
    "        LLS = np.array([])\n",
    "        LPS = np.array([])\n",
    "        RRS = np.array([])\n",
    "        RPS = np.array([])\n",
    "        results = []\n",
    "        ids_test = []\n",
    "        \n",
    "        cleaned_train = pd.read_csv(path + 'hms-harmful-brain-activity-classification/cleaned_train.csv')\n",
    "        cleaned_train = cleaned_train[cleaned_train['is_center'] == True]\n",
    "        \n",
    "        try:\n",
    "            df1 = pd.read_csv(path_for_file)\n",
    "            current_ids = set(df1['eeg_ids'])\n",
    "            print(current_ids)\n",
    "        except:\n",
    "            current_ids = []\n",
    "        \n",
    "        if eeg_id in current_ids:\n",
    "            print(\"skip\")\n",
    "            continue\n",
    "        \n",
    "#         if i != 0 and non_nan_count == 0:\n",
    "#             print(\"Skip\")\n",
    "#             continue\n",
    "        \n",
    "        log.critical(f\"{i} out of {len(ids)}\")\n",
    "        try:\n",
    "             # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "            eeg = pd.read_parquet(path + f'hms-harmful-brain-activity-classification/train_eegs/{eeg_id}.parquet')\n",
    "        except Exception as e:\n",
    "            print(\"ERROR\")\n",
    "            print(e)\n",
    "    \n",
    "        ids_test.append(eeg_id)\n",
    "        middle = (len(eeg)-10_000)//2\n",
    "        eeg = eeg.iloc[middle:middle+10_000]\n",
    "\n",
    "\n",
    "        if display: plt.figure(figsize=(10,7))\n",
    "        signals_int = []\n",
    "        LL = np.array([])\n",
    "        LP = np.array([])\n",
    "        RR = np.array([])\n",
    "        RP = np.array([])\n",
    "        for k in range(4):\n",
    "            COLS = FEATS[k]\n",
    "            for kk in range(4):\n",
    "\n",
    "                # COMPUTE PAIR DIFFERENCES\n",
    "                x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
    "\n",
    "                # FILL NANS\n",
    "                m = np.nanmean(x)\n",
    "                if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "                else: x[:] = 0\n",
    "\n",
    "                # DENOISE\n",
    "                if USE_WAVELET:\n",
    "                    x = denoise(x, wavelet=USE_WAVELET)\n",
    "                signals_int.append(x)\n",
    "\n",
    "        signals = np.stack(signals_int, axis=0)\n",
    "        LL = signals[0] + signals[1] + signals[2] + signals[3]\n",
    "        LP = signals[4] + signals[5] + signals[6] + signals[7]\n",
    "        RR = signals[8] + signals[9] + signals[10] + signals[11]\n",
    "        RP = signals[12] + signals[13] + signals[14] + signals[15]\n",
    "\n",
    "        id_data = np.full(10000, eeg_id)\n",
    "        time = np.arange(0, 10000, 1)\n",
    "        # id_data = np.expand_dims(id_data, axis=1)\n",
    "        # time = np.expand_dims(time, axis=1)\n",
    "        LL = np.expand_dims(LL, axis=1)\n",
    "        LP = np.expand_dims(LP, axis=1)\n",
    "        RR = np.expand_dims(RR, axis=1)\n",
    "        RP = np.expand_dims(RP, axis=1)\n",
    "\n",
    "        # ids_data.append(id_data)\n",
    "        # times_data.append(time)\n",
    "        # LLS.append(LL)\n",
    "        # LPS.append(LP)\n",
    "        # RRS.append(RR)\n",
    "        # RPS.append(RP)\n",
    "        result = cleaned_train.loc[(cleaned_train['eeg_id'] == eeg_id) & (cleaned_train['is_center'] == True), 'expert_consensus'].values[0]\n",
    "        results.append([result] * len(LL))\n",
    "\n",
    "        ids_data = np.append(ids_data, id_data)\n",
    "        times_data = np.append(times_data, time)\n",
    "        LLS = np.append(LLS, LL)\n",
    "        LPS = np.append(LPS, LP)\n",
    "        RRS = np.append(RRS, RR)\n",
    "        RPS = np.append(RPS, RP)\n",
    "\n",
    "        signals = np.stack([ids_data, times_data, LLS, LPS, RRS, RPS], axis = 1)\n",
    "        # signals = np.squeeze(signals, axis=2)\n",
    "\n",
    "        df = pd.DataFrame(signals)\n",
    "\n",
    "        # Rename columns\n",
    "        df.columns = ['id', 'time', 'LL', 'LP', 'RR', 'RP']\n",
    "        # Set the index\n",
    "        df.set_index('time', inplace=True)\n",
    "        # Reset the index\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        # Distributor = MultiprocessingDistributor(n_workers=3,\n",
    "        #                                      disable_progressbar=False,\n",
    "        #                                      progressbar_title=\"Feature Extraction\")\n",
    "\n",
    "        # Call TSFresh on the data\n",
    "        # extracted_features = extract_features(df, column_id=\"id\", column_sort=\"time\", distributor=Distributor )\n",
    "        log.critical(f\"Extraction started\")\n",
    "        settings = tsfresh.feature_extraction.settings.EfficientFCParameters()\n",
    "        output = extract_features(df,\n",
    "                                                         column_id='id', column_sort='time',\n",
    "                                                          default_fc_parameters=settings)\n",
    "        \n",
    "        if len(output) > 1:\n",
    "            print(output)\n",
    "        output.insert(0, 'eeg_id', None)\n",
    "        output['eeg_id'] = eeg_id\n",
    "        try:\n",
    "            df1 = pd.read_csv(path_for_file)\n",
    "            df_concat = pd.concat([df1, output], axis=0, ignore_index=True, keys=None)\n",
    "            df_concat.drop(df_concat.columns[df_concat.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "            df_concat.to_csv(path_for_file)\n",
    "            print(str(len(df_concat) / len(ids)) + '%')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            output.to_csv(path_for_file)\n",
    "        \n",
    "#         print(len(cleaned_train.columns))\n",
    "#         if len(cleaned_train.columns) == 18:\n",
    "#             output['eeg_id'] = [eeg_id]\n",
    "#             cleaned_train = pd.merge(cleaned_train, output, on='eeg_id', how='left')\n",
    "#         else:\n",
    "#             cols_to_update = cleaned_train.columns[col_index:]\n",
    "#             row_to_update = cleaned_train[cleaned_train['eeg_id'] == eeg_id].iloc[0]\n",
    "\n",
    "#             # Step 2: Update the values in DataFrame 'a'\n",
    "#             cleaned_train.loc[cleaned_train['eeg_id'] == eeg_id, cols_to_update] = output.loc[:, cols_to_update].values[0]\n",
    "\n",
    "#         cleaned_train.to_csv('gcs/hms-harmful-brain-activity-classification/cleaned_train.csv')\n",
    "            \n",
    "\n",
    "    unique_values = set([item for row in results for item in row])\n",
    "    mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "    results = [[mapping[item] for item in row] for row in results]\n",
    "    results = [item for sublist in results for item in sublist]\n",
    "    results = pd.Series(results)\n",
    "\n",
    "    results = cleaned_train[['eeg_id', 'expert_consensus']]\n",
    "    results = pd.Series(results['expert_consensus'].values, index=results['eeg_id'])\n",
    "    results = results.loc[results.index.isin(ids_test)]\n",
    "    # Convert the categorical Series to a categorical data type\n",
    "    results = results.astype('category')\n",
    "    # Convert the categorical values to numerical codes\n",
    "    results = results.cat.codes\n",
    "\n",
    "\n",
    "\n",
    "    signals = np.stack([ids_data, times_data, LLS, LPS, RRS, RPS], axis = 1)\n",
    "    # signals = np.squeeze(signals, axis=2)\n",
    "\n",
    "    df = pd.DataFrame(signals)\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = ['id', 'time', 'LL', 'LP', 'RR', 'RP']\n",
    "    # Set the index\n",
    "    df.set_index('time', inplace=True)\n",
    "    # Reset the index\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Distributor = MultiprocessingDistributor(n_workers=3,\n",
    "    #                                      disable_progressbar=False,\n",
    "    #                                      progressbar_title=\"Feature Extraction\")\n",
    "\n",
    "    # Call TSFresh on the data\n",
    "    # extracted_features = extract_features(df, column_id=\"id\", column_sort=\"time\", distributor=Distributor )\n",
    "    log.critical(f\"Extraction started\")\n",
    "    settings = tsfresh.feature_extraction.settings.EfficientFCParameters()\n",
    "    features_filtered_direct = extract_features(df,\n",
    "                                                     column_id='id', column_sort='time',\n",
    "                                                      default_fc_parameters=settings)\n",
    "    # extracted_features['eeg_id'] = int(eeg_id)\n",
    "    \n",
    "    return features_filtered_direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train = pd.read_csv(path + 'hms-harmful-brain-activity-classification/cleaned_train.csv')\n",
    "cleaned_train = cleaned_train[cleaned_train['is_center'] == True]\n",
    "ids = set(cleaned_train['eeg_id'])\n",
    "# df1 = pd.read_csv(path + 'hms-harmful-brain-activity-classification/new_features.csv')\n",
    "# current_ids = set(df1['eeg_id'])\n",
    "# diff = list(ids - current_ids)[:500]\n",
    "diff = list(ids)[0 + 500 * offset:500 + 500 * offset]\n",
    "diff = set(diff)\n",
    "# features = spectrogram_from_eeg(ids)\n",
    "spectrogram_from_eeg(diff)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
